{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install speechrecognition gtts deep-translator rank-bm25 sentence-transformers playsound pickle-mixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygameNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pygame-2.6.1-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Downloading pygame-2.6.1-cp312-cp312-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/10.6 MB 670.4 kB/s eta 0:00:16\n",
      "   - -------------------------------------- 0.5/10.6 MB 670.4 kB/s eta 0:00:16\n",
      "   --- ------------------------------------ 1.0/10.6 MB 914.5 kB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 1.3/10.6 MB 986.4 kB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.6/10.6 MB 1.1 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.4/10.6 MB 1.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.6/10.6 MB 1.5 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.7/10.6 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.5/10.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 5.2/10.6 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 6.6/10.6 MB 2.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.3/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.4/10.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.0/10.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.6.1\n"
     ]
    }
   ],
   "source": [
    "pip install pygame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import time\n",
    "import pandas as pd\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from deep_translator import GoogleTranslator\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import pickle\n",
    "\n",
    "# Function to provide progress updates\n",
    "def update_checkpoint(message):\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] {message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_or_load_bm25(dataset_path, cache_path=\"bm25_cache.pkl\"):\n",
    "    try:\n",
    "        # Try loading cached BM25 model and tokenized corpus\n",
    "        with open(cache_path, \"rb\") as f:\n",
    "            bm25, df = pickle.load(f)\n",
    "        update_checkpoint(\"Loaded BM25 model from cache.\")\n",
    "    except FileNotFoundError:\n",
    "        # If no cache is found, build BM25 from scratch and save it\n",
    "        update_checkpoint(\"Building BM25 model from scratch...\")\n",
    "        df = pd.read_csv(dataset_path, low_memory=False)\n",
    "        df['Answer'] = df['Answer'].astype(str).fillna(\"\")\n",
    "        tokenized_corpus = [doc.split(\" \") for doc in df['Answer'] if isinstance(doc, str)]\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "        # Cache the BM25 model and tokenized dataset for future use\n",
    "        with open(cache_path, \"wb\") as f:\n",
    "            pickle.dump((bm25, df), f)\n",
    "        update_checkpoint(\"BM25 model built and saved to cache.\")\n",
    "    return bm25, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_cache = {}\n",
    "\n",
    "def translate_text(text):\n",
    "    if text in translation_cache:\n",
    "        update_checkpoint(\"Using cached translation.\")\n",
    "        return translation_cache[text]\n",
    "    try:\n",
    "        update_checkpoint(\"Translating text from Hindi to English...\")\n",
    "        translated_text = GoogleTranslator(source='hi', target='en').translate(text)\n",
    "        translation_cache[text] = translated_text\n",
    "        update_checkpoint(f\"Translation successful: '{translated_text}'\")\n",
    "        return translated_text\n",
    "    except Exception as e:\n",
    "        update_checkpoint(f\"Translation error: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_cache = {}\n",
    "\n",
    "def translate_text(text):\n",
    "    if text in translation_cache:\n",
    "        update_checkpoint(\"Using cached translation.\")\n",
    "        return translation_cache[text]\n",
    "    try:\n",
    "        update_checkpoint(\"Translating text from Hindi to English...\")\n",
    "        translated_text = GoogleTranslator(source='hi', target='en').translate(text)\n",
    "        translation_cache[text] = translated_text\n",
    "        update_checkpoint(f\"Translation successful: '{translated_text}'\")\n",
    "        return translated_text\n",
    "    except Exception as e:\n",
    "        update_checkpoint(f\"Translation error: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Global variable to cache the QA pipeline\n",
    "qa_pipeline = None\n",
    "\n",
    "def load_qa_model():\n",
    "    global qa_pipeline\n",
    "    if qa_pipeline is None:\n",
    "        update_checkpoint(\"Loading Question-Answering model...\")\n",
    "        qa_pipeline = pipeline(\"question-answering\", model=\"deepset/bert-base-cased-squad2\")\n",
    "        update_checkpoint(\"Question-Answering model loaded.\")\n",
    "    return qa_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_audio():\n",
    "    r = sr.Recognizer()\n",
    "\n",
    "    try:\n",
    "        update_checkpoint(\"Starting audio capture...\")\n",
    "        with sr.Microphone() as source:\n",
    "            r.adjust_for_ambient_noise(source)\n",
    "            print(\"Speak something...\")\n",
    "            audio = r.listen(source)\n",
    "        update_checkpoint(\"Audio capture successful.\")\n",
    "\n",
    "        # Recognize speech using Google Speech Recognition\n",
    "        update_checkpoint(\"Converting speech to text...\")\n",
    "        text = r.recognize_google(audio)\n",
    "        update_checkpoint(f\"Speech recognized: '{text}'\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        update_checkpoint(\"Speech recognition error: Could not understand audio.\")\n",
    "        return None\n",
    "    except sr.RequestError:\n",
    "        update_checkpoint(\"Speech recognition service unavailable.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        update_checkpoint(f\"Unexpected error: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query, bm25, df):\n",
    "    try:\n",
    "        # Tokenize the query and perform BM25 search\n",
    "        update_checkpoint(\"Performing BM25 retrieval...\")\n",
    "        query_tokens = query.split(\" \")\n",
    "        results = bm25.get_top_n(query_tokens, df['Answer'], n=5)\n",
    "        update_checkpoint(\"BM25 retrieval successful.\")\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        update_checkpoint(f\"Retrieval error: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(query, context):\n",
    "    try:\n",
    "        update_checkpoint(\"Performing question-answering...\")\n",
    "        qa_pipeline = load_qa_model()\n",
    "        result = qa_pipeline(question=query, context=context[0])  # Use the first document for QA\n",
    "        update_checkpoint(\"Question-answering successful.\")\n",
    "        return result['answer']\n",
    "    except Exception as e:\n",
    "        update_checkpoint(f\"QA error: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "\n",
    "def play_audio_with_pygame(filename):\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(filename)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    # Wait for the audio to finish playing\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        pygame.time.Clock().tick(10)\n",
    "\n",
    "def text_to_speech(text, filename=\"output.mp3\"):\n",
    "    try:\n",
    "        update_checkpoint(\"Converting answer to speech...\")\n",
    "        speech = gTTS(text=text, lang='en', slow=False)\n",
    "        speech.save(filename)\n",
    "        update_checkpoint(f\"Speech saved as '{filename}'.\")\n",
    "\n",
    "        # Play the audio using Pygame\n",
    "        play_audio_with_pygame(filename)\n",
    "\n",
    "    except Exception as e:\n",
    "        update_checkpoint(f\"TTS error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:23:11] Starting audio capture...\n",
      "Speak something...\n",
      "[00:23:23] Audio capture successful.\n",
      "[00:23:23] Converting speech to text...\n",
      "[00:23:26] Speech recognized: 'Kuchh BNP shulk Vaid ho sakte hain lekin parinaam theek hai sanyukt rashtra'\n",
      "[00:23:26] Translating text from Hindi to English...\n",
      "[00:23:27] Translation successful: 'Some BNP charges may be valid but the result is good United Nation'\n",
      "[00:23:45] Loaded BM25 model from cache.\n",
      "[00:23:45] Performing BM25 retrieval...\n",
      "[00:23:49] BM25 retrieval successful.\n",
      "[00:23:49] Performing question-answering...\n",
      "[00:23:49] Question-answering successful.\n",
      "[00:23:49] Converting answer to speech...\n",
      "[00:23:50] Speech saved as 'output.mp3'.\n"
     ]
    }
   ],
   "source": [
    "def main_pipeline():\n",
    "    # Step 1: Capture Audio\n",
    "    query_text = capture_audio()\n",
    "\n",
    "    if query_text:\n",
    "        # Step 2: Translate Text (if needed, based on language)\n",
    "        translated_query = translate_text(query_text)\n",
    "\n",
    "        if translated_query:\n",
    "            # Step 3: Retrieve Relevant Documents\n",
    "            bm25, df = build_or_load_bm25(\"data\\\\new_csv_file.csv\")\n",
    "            relevant_docs = retrieve_documents(translated_query, bm25, df)\n",
    "\n",
    "            if relevant_docs:\n",
    "                # Step 4: Answer Question using retrieved documents\n",
    "                answer = answer_question(translated_query, relevant_docs)\n",
    "\n",
    "                if answer:\n",
    "                    # Step 5: Convert Answer to Speech\n",
    "                    text_to_speech(answer)\n",
    "\n",
    "# Run the full pipeline\n",
    "main_pipeline()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
